Download Virtual Box - 
https://www.virtualbox.org/wiki/Downloads

Ubuntu download: 
https://ubuntu.com/download/desktop/thank-you?version=20.04.3&architecture=amd64

Download Desktop version

After installation of Ubuntu, adjust screen resolution.

Go to terminal.
Try python3 
sudo install python3-pip
pip3 install jupyter

1) pip3 install notebook

2) sudo apt install jupyter-notebook

To close jupyter notebook - at terminal do ctrl+c


sudo apt-get update
sudo apt-get install default-jre
Verify - java -version

sudo apt-get install scala
Verify- scala -version

pip3 install py4j 


Download - Apache Spark 2.1.0 bin hadoop 2.7 - to be in sync with the course
Move the downloaded file to home directory

Unzip the file usig - 
sudo tar -zxvf file_name

Add Spark to Environment viriables- 
export SPARK_HOME='home/himangshu/spark2.1.0-bin-hadoop2.7'
export PATH=$SPARK_PATH:$PATH
export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH
export PYSPARK_DRIVER_PYTHON="jupyter"
export PYSPARK_DRIVER_PYTHON_OPTS="notebook"
export PYSPARK_PYTHON=python3

Change permission - 
sudo chmod 777 spark2.1.0-bin-hadoop2.7.tgz




Change home direcotry to /usr/src/Python3.5
Install Spark into this direcotry
Install py4j into spark/python
export all paths in Python3.5
Run jupyter notebook from python3.5 

Python3.5 path - /usr/src/Python3.5/

Install py4j==0.10.4 into python directory of spark2.1.0-bin-hadoop2.7
cd spark2.1.0-bin-hadoop2.7
sudo chmod 777 python
cd python
pip3 install py4j==0.10.4 -t .

-----------------------
To fix the pyspark not found issue - 
pip3 install findspark
import findspark
findspark.init('pat of the spark home directory')
import pyspark

 